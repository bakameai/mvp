# BAKAME IVR - Advanced Multi-Stage Evaluation Engine

## üß† Overview

The BAKAME IVR Evaluation Engine implements a sophisticated, multi-layered assessment system that goes beyond simple recall testing. It provides emotionally intelligent, curriculum-aligned evaluation across all Bloom's Taxonomy stages with adaptive feedback and progression tracking.

## üèóÔ∏è Architecture

### Core Components

1. **YAML-Based Evaluation Schemas** - Structured assessment definitions per module/stage
2. **Multi-Factor Scoring Engine** - Keyword + Structure + LLM evaluation
3. **Emotional Intelligence Layer** - Sentiment detection and adaptive feedback
4. **Progression Tracking** - 3/5 pass advancement with demotion support
5. **IVR-Optimized Prompts** - ‚â§10 second voice-friendly questions
6. **Analytics Dashboard** - Bloom stage heatmaps and performance metrics

### System Flow

```
START ‚Üí Load YAML Schema ‚Üí Deliver IVR Prompt ‚Üí Record Response ‚Üí 
Transcribe (ASR) ‚Üí Multi-Factor Evaluation ‚Üí Emotional Analysis ‚Üí 
Select Feedback ‚Üí Log Results ‚Üí Check Advancement ‚Üí Return Audio
```

## üìÅ YAML Schema Structure

Each evaluation schema is stored in `/docs/curriculum/{module}/{stage}.yaml` with the following structure:

### Schema Template

```yaml
stage: remember|understand|apply|analyze|evaluate|create
module: grammar|composition|math|debate|comprehension
goal: "Clear learning objective for this stage"
source: "Educational resource reference"

ivr_prompt: |
  Multi-line IVR-friendly prompt (‚â§10 seconds)
  Designed for voice interaction with clear instructions

expected_structure:
  - "‚â•2 complete sentences"
  - "specific content requirements"
  - "structural expectations"

llm_scoring_criteria:
  temperature: 0.2  # Low temp for consistent evaluation
  rules:
    - "specific evaluation criteria"
    - "measurable learning outcomes"
    - "cultural context considerations"

keywords:
  positive: ["correct", "good", "understand"]
  negative: ["wrong", "confused", "don't know"]

feedback_templates:
  pass: "Encouraging success message"
  fail_hint: "Helpful guidance for improvement"
  fail_repeat: "Supportive retry encouragement"
  encouragement: "General motivational message"

emotional_responses:
  hesitation: "Response for uncertain students"
  confusion: "Clarification for confused students"
  frustration: "Support for frustrated students"

advancement_criteria:
  pass_threshold: 0.6
  advancement_rule: "3 passes out of 5 attempts"
  demotion_rule: "3 consecutive failures"

assessment_weights:
  keyword_match: 0.4
  sentence_structure: 0.3
  llm_evaluation: 0.3
```

## üéØ Module-Specific Implementation

### Grammar Module (Technical Language Skills)

**Focus**: Verb tenses, sentence structure, error correction
**Example Evaluation**: Past tense usage in narrative context

```yaml
# grammar/apply.yaml
ivr_prompt: |
  Tell me about what you did yesterday. Use at least two sentences 
  and make sure to use past tense verbs. What did you do yesterday?

keywords:
  positive: ["went", "played", "ate", "walked", "studied"]
  negative: ["will", "going to", "tomorrow", "next"]
```

### Composition Module (Creative Expression)

**Focus**: Storytelling, cultural context, creative writing
**Example Evaluation**: Original story creation with moral lessons

```yaml
# composition/create.yaml
ivr_prompt: |
  Think of someone in your community who showed great courage. 
  Tell me their story with beginning, middle, and end. 
  What can we learn from them?

expected_structure:
  - "original narrative with clear structure"
  - "character emotions and motivations"
  - "cultural or community context"
  - "meaningful lesson or theme"
```

### Math Module (Mental Mathematics)

**Focus**: Practical problem-solving, mental calculation techniques
**Example Evaluation**: Real-world market scenarios

```yaml
# math/apply.yaml
ivr_prompt: |
  You're at Kigali market. You bought 3 pineapples at 450 francs each, 
  and paid with 2000 francs. How much change should you get? 
  Tell me your answer and how you calculated it.

keywords:
  positive: ["650", "1350", "multiply", "subtract", "francs"]
  negative: ["don't know", "can't", "too hard"]
```

### Debate Module (Critical Thinking)

**Focus**: Argument construction, balanced reasoning, civic engagement
**Example Evaluation**: Multi-perspective analysis

```yaml
# debate/evaluate.yaml
ivr_prompt: |
  Should students wear uniforms? Give one reason FOR and one AGAINST. 
  Then tell me your opinion and explain why you think that way.

expected_structure:
  - "argument supporting uniforms"
  - "argument opposing uniforms"
  - "clear personal position"
  - "reasoning connectors (because, however)"
```

### Comprehension Module (Reading & Communication)

**Focus**: Text analysis, information synthesis, oral tradition
**Example Evaluation**: Story interpretation and personal connection

## ü§ñ Multi-Factor Scoring System

### 1. Keyword Matching (40% weight)
- **Positive Keywords**: Increase score when present
- **Negative Keywords**: Decrease score when detected
- **Contextual Relevance**: Module-specific vocabulary assessment
- **Cultural Sensitivity**: Rwandan English patterns recognition

### 2. Sentence Structure (30% weight)
- **Completeness**: Full sentences vs. fragments
- **Complexity**: Word count and sentence variety
- **Grammar Patterns**: Subject-verb agreement, tense consistency
- **Coherence**: Logical flow and organization

### 3. LLM Evaluation (30% weight)
- **Temperature**: 0.2 for consistent assessment
- **Criteria-Based**: Schema-specific evaluation rules
- **Cultural Context**: Ubuntu philosophy and Rwandan values
- **Effort Recognition**: Encourages attempt over perfection

### Scoring Formula
```python
final_score = (
    keyword_score * 0.4 +
    structure_score * 0.3 +
    llm_score * 0.3
)
is_pass = final_score >= 0.6
```

## ‚ù§Ô∏è Emotional Intelligence Layer

### Emotional State Detection

**Hesitation Markers**: "um", "uh", "maybe", "not sure"
```
Response: "Take your time. Think about the time word 'yesterday'."
```

**Confusion Markers**: "don't understand", "confused", "what"
```
Response: "Let me help you. When we talk about yesterday, we use past tense verbs."
```

**Frustration Markers**: "hard", "difficult", "can't", "give up"
```
Response: "You're doing great! Learning takes practice. Let's break it down together."
```

### Adaptive Feedback Selection

1. **Emotional State Priority**: Address emotional needs first
2. **Performance-Based**: Success vs. failure feedback paths
3. **Cultural Sensitivity**: Ubuntu philosophy integration
4. **Encouragement Focus**: Growth mindset reinforcement

### Temperature-Based Responses

- **Assessment**: 0.2 (consistent, objective evaluation)
- **Encouragement**: 1.8 (warm, dynamic motivation)
- **Hints**: 1.0 (balanced guidance)
- **Facts**: 1.6 (engaging cultural context)

## üìä Progression Logic

### Advancement Rules

**Promotion**: 3 passes out of last 5 attempts
```
remember ‚Üí understand ‚Üí apply ‚Üí analyze ‚Üí evaluate ‚Üí create
```

**Demotion**: 3 consecutive failures
```
Provides additional support at lower stage before re-attempting
```

### Stage Tracking
```python
# Redis storage structure
user:{phone_number}:
  curriculum_stages:
    grammar: "apply"
    composition: "understand"
    math: "remember"
  evaluation_history:
    grammar: [
      {
        "timestamp": "2025-08-29T02:45:13Z",
        "stage": "apply",
        "overall_score": 0.75,
        "is_pass": true,
        "emotional_state": "neutral",
        "feedback": "Great job! Your grammar is improving!"
      }
    ]
```

## üé§ IVR Integration

### Voice Prompt Design

**Length**: ‚â§10 seconds for attention span
**Clarity**: Simple, direct instructions
**Cultural Context**: Rwandan examples and scenarios
**Engagement**: Questions that invite personal response

### Evaluation Flow

1. **Trigger**: Student says "evaluate", "test", or "assessment"
2. **Module Selection**: Based on recent activity or keywords
3. **Stage Detection**: Current Bloom's taxonomy level
4. **Prompt Delivery**: YAML-defined IVR prompt
5. **Response Recording**: Twilio voice capture
6. **Transcription**: ElevenLabs voice processing
7. **Multi-Factor Evaluation**: Comprehensive scoring
8. **Feedback Selection**: Emotionally appropriate response
9. **Progression Check**: Advancement/demotion logic
10. **Audio Response**: TTS with appropriate tone

### Example Interaction

```
System: "Great! Let's do a grammar evaluation at apply level. 
         Tell me about what you did yesterday. Use at least two 
         sentences and make sure to use past tense verbs."

Student: "Yesterday I go to school and I play with friends."

System: [Evaluation: keyword_score=0.3, structure_score=0.7, llm_score=0.4]
         [Final Score: 0.47, FAIL]
         [Emotional State: neutral]
         
         "Good try! Remember: yesterday = past time, so we say 'went' 
         and 'played' not 'go' and 'play'. Let's try another one."
```

## üìà Analytics Dashboard

### Bloom Stage Heatmap

Visual representation of student performance across all stages:

```json
{
  "grammar": {
    "remember": {"avg_score": 0.85, "pass_rate": 0.90, "attempts": 45},
    "understand": {"avg_score": 0.72, "pass_rate": 0.75, "attempts": 32},
    "apply": {"avg_score": 0.68, "pass_rate": 0.65, "attempts": 28}
  }
}
```

### Performance Metrics

- **Module Performance**: Success rates per learning domain
- **Stage Difficulty**: Bloom's taxonomy progression analysis
- **Emotional Distribution**: Student sentiment patterns
- **Cultural Effectiveness**: Rwandan context integration success

### Export Capabilities

**CSV Format**: Student progress, evaluation history, performance trends
**API Endpoints**: Real-time analytics for external systems
**Visualization**: Charts and graphs for educational insights

## üîß Technical Implementation

### Service Architecture

```python
# Core Services
evaluation_engine.py      # Main evaluation orchestration
llama_service.py          # LLM integration with evaluation context
curriculum_service.py     # Legacy assessment system integration
redis_service.py          # Session and progression storage
elevenlabs_service.py     # ElevenLabs conversational AI integration
```

### Database Schema

**Redis Storage**:
- User context and session management
- Evaluation history and progression tracking
- Emotional state and feedback patterns

**PostgreSQL Logging**:
- Detailed evaluation records
- Performance analytics
- Cultural adaptation metrics

### API Endpoints

```python
# Evaluation System
GET  /admin/evaluation/analytics     # System-wide evaluation metrics
GET  /admin/curriculum/student-progress  # Individual progress with heatmaps
POST /webhook/call                   # Voice interaction with evaluation

# Schema Management
GET  /admin/evaluation/schemas       # Available evaluation schemas
POST /admin/evaluation/reload        # Reload YAML schemas
```

## üß™ Testing & Validation

### Test Coverage

1. **YAML Schema Loading**: All modules and stages
2. **Multi-Factor Scoring**: Component and integration tests
3. **Emotional Detection**: Sentiment analysis accuracy
4. **Progression Logic**: Advancement and demotion rules
5. **IVR Integration**: End-to-end voice evaluation flows
6. **Cultural Sensitivity**: Rwandan context appropriateness

### Performance Benchmarks

- **Response Time**: <2 seconds for evaluation completion
- **Accuracy**: >85% correlation with human evaluators
- **Cultural Relevance**: >90% appropriate Rwandan context
- **Emotional Recognition**: >80% sentiment detection accuracy

### Quality Assurance

```python
# Test evaluation with temperature 1.8
async def test_evaluation_flow():
    result = await evaluation_engine.evaluate_response(
        "Yesterday I went to school and played with friends",
        "grammar", "apply", user_context
    )
    assert result["is_pass"] == True
    assert result["emotional_state"] in ["neutral", "hesitation", "confusion", "frustration"]
```

## üåç Cultural Integration

### Ubuntu Philosophy

**Interconnectedness**: "I am because we are" reflected in community-focused prompts
**Collective Learning**: Emphasis on shared knowledge and mutual support
**Respect for Elders**: Traditional wisdom integration in storytelling evaluations

### Rwandan Context

**Local Examples**: Market scenarios, community stories, cultural references
**Language Patterns**: Accommodation for Rwandan English characteristics
**Educational Values**: Alignment with national curriculum and cultural priorities

### Accessibility

**Low-Resource Design**: Optimized for basic phones and limited connectivity
**Multilingual Support**: Kinyarwanda integration preparation
**Economic Sensitivity**: Free access with optional premium features

## üöÄ Future Enhancements

### Advanced Features

1. **Voice Emotion Analysis**: ElevenLabs sentiment API integration
2. **Adaptive Difficulty**: Dynamic schema adjustment based on performance
3. **Peer Comparison**: Anonymous benchmarking against similar learners
4. **Cultural Storytelling**: AI-generated Rwandan folktales for comprehension

### Research Opportunities

1. **Educational Effectiveness**: Longitudinal learning outcome studies
2. **Cultural Adaptation**: Cross-cultural evaluation methodology research
3. **Emotional Intelligence**: AI empathy in educational contexts
4. **Language Scaffolding**: Optimal support for English language learners

### Technical Roadmap

1. **Real-time Analytics**: Live evaluation performance monitoring
2. **Machine Learning**: Predictive modeling for student success
3. **Integration APIs**: Third-party educational platform connections
4. **Mobile Apps**: Companion applications for enhanced learning

## üìö References

### Educational Framework
- **Bloom's Taxonomy**: Cognitive learning objectives hierarchy
- **Ubuntu Philosophy**: African humanist philosophy integration
- **Culturally Responsive Teaching**: Pedagogical approach for diverse learners

### Technical Standards
- **YAML Schema**: Structured evaluation definition format
- **Redis Session Management**: High-performance user state storage
- **Twilio Voice API**: Telephony integration for voice interactions
- **ElevenLabs AI**: Advanced conversational AI for evaluation

### Open Educational Resources
- **Grammar**: Speak English: 30 Days to Better English
- **Composition**: Things Fall Apart (Chinua Achebe)
- **Math**: Secrets of Mental Math
- **Debate**: Code of the Debater (Alfred Snider)
- **Comprehension**: Art of Public Speaking

---

**BAKAME Evaluation Engine** - Transforming voice-based education through intelligent, culturally-aware assessment that recognizes effort, encourages growth, and celebrates learning in the Rwandan context.
